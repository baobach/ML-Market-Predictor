{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Ideation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pulling\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import yfinance as yf\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV,\n",
    "    TimeSeriesSplit,\n",
    "    cross_val_score\n",
    ")\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score,\n",
    "    auc\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `yfinance` package to download daily trading data from Yahoo Finance. The recommended data should span a 5-year period, which is considered sufficient. The downloaded data will be saved in the `.csv` format and can be accessed later using the file name `SPY1D.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for TSLA and store as csv file\n",
    "spy = yf.download(\"SPY\", start = '2008-10-16', end = '2023-10-16' , interval='1D')\n",
    "spy.to_csv('SPY1D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy = pd.read_csv('../module_4/SPY1D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the downloaded data\n",
    "spy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize asset path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(spy, x= 'Date', y='Adj Close', labels = {'Adj Close': 'Close Price (USD)'}, title = 'S&P 500 ETF Trust (SPY) Daily')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the distribution of returns and the closing price movement to identify any trends or significant information regarding the returns that could be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy['Returns'] = np.log(spy['Adj Close']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Plot the return histogram\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "spy['Returns'].hist(bins=50, ax=ax1)\n",
    "ax1.set_xlabel('Return')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Return distribution')\n",
    "\n",
    "# Plot the normal distribution\n",
    "mu = spy['Returns'].mean()\n",
    "sigma = spy['Returns'].std()\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "plt.plot(x, norm.pdf(x, mu, sigma))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return is definately not normally distributed. There is a high peak and very fat tails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Specify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the feature list table from the exam, we will generate features based on the historical data we have acquired. Additionally, I've included 10 lagged prices in the feature list, operating on the assumption that historical data may possess predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features (predictors) list\n",
    "features_list = []\n",
    "# Intraday price range\n",
    "spy['OC'] = spy['Open'] - spy['Close']\n",
    "spy['HL'] = spy['High'] - spy['Low']\n",
    "# Sign of return or momentum\n",
    "spy['Sign'] = np.sign(spy.Returns)\n",
    "\n",
    "# Append feature list\n",
    "features_list.append('OC')\n",
    "features_list.append('HL')\n",
    "features_list.append('Sign')\n",
    "\n",
    "# Pass Returns, Volatility\n",
    "for r in range(10, 65, 5):\n",
    "    spy['Ret_'+str(r)] = spy.Returns.rolling(r).sum()\n",
    "    spy['Std_'+str(r)] = spy.Returns.rolling(r).std()\n",
    "    features_list.append('Ret_'+str(r))\n",
    "    features_list.append('Std_'+str(r))\n",
    "\n",
    "# SMA and EMA\n",
    "for a in range(20, 200, 10):\n",
    "    spy['SMA_'+str(r)] = spy['Adj Close'].rolling(r).mean()\n",
    "    spy['EMA_'+str(a)] = spy['Adj Close'].ewm(span = a).mean()\n",
    "    features_list.append('SMA_'+str(r))\n",
    "    features_list.append('EMA_'+str(r))\n",
    "\n",
    "# Lag price\n",
    "for lag in range(1, 10):\n",
    "    spy['lag_' + str(lag)] = spy['Adj Close'].shift(lag)\n",
    "\n",
    "# Drop NaN values\n",
    "spy.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Target\n",
    "spy['Target'] = np.where(spy['Adj Close'].shift(-1) > 0.995 * spy['Adj Close'],1,0)\n",
    "# Check output\n",
    "spy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to split the data into the `train_set` and `test_set` and perform exploratory data analysis (EDA) and data cleaning exclusively on the `train_set` to prevent any potential data leakage from the EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the original data\n",
    "data = spy.copy().set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the features matrix `X`\n",
    "X = data.drop(['Open', 'Close', 'High', 'Low', 'Adj Close', 'Returns', 'Volume', 'Target'],axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label or target vector `y`\n",
    "y = data['Target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets into training and testing data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "# Output the train and test data size\n",
    "print(f\"Train and Test Size {len(X_train)}, {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a classification problem, it's important to check for any imbalances in our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class frequency\n",
    "c = y_train.value_counts()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is imbalanced. We will create a weight function and subsequently use it to address our problem when building a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight function\n",
    "def cwts(label):\n",
    "    c0, c1 = np.bincount(label)\n",
    "    w0=(1/c0)*(len(label))/2 \n",
    "    w1=(1/c1)*(len(label))/2 \n",
    "    return {0: w0, 1: w1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class weights\n",
    "class_weight = cwts(y_train)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi collinearity features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collinear features can adversely affect our model's performance. We will create a function to help us identify and drop these features, and then apply it to our test dataset. Let's also visualize our correlation matrix using the `sns.heatmap()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 22))\n",
    "\n",
    "# Identify features that are highly correlated\n",
    "sns.heatmap(X_train.corr()>0.9,\n",
    "            annot=True,\n",
    "            annot_kws={\"size\": 8},\n",
    "            fmt=\".2f\",\n",
    "            linewidth=.5,\n",
    "            cmap=\"coolwarm\",\n",
    "            cbar=True); #cmap=\"crest\", virids, magma\n",
    "\n",
    "plt.title('Features Set Correlations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is also a crucial factor in our model's accuracy. We need to scale the data before inputting it into our learning algorithm. We can easily identify features that require scaling by using the `sns.boxplot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study the distribution\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(X_train))\n",
    "plt.xlabel(' ')\n",
    "plt.title('Boxplot of Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can identify features that require scaling by using the `pd.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features exhibit significantly higher values compared to the others. For these features, we will use the `MinMaxScaler()` method to scale them appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our exploratory data analysis (EDA) process, we have identified multicollinear features. We will develop a function to eliminate these features and then implement it on our training data. Subsequently, we will apply the same function to our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first feature that is correlated with any other feature\n",
    "def correlated_features(data, threshold=0.9):\n",
    "    col_corr = set()\n",
    "    corr_matrix = X_train.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of remaining features\n",
    "drop_correlated_features = correlated_features(X_train, threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the highly correlated features\n",
    "X_train_drop = X_train.drop(drop_correlated_features, axis=1)\n",
    "X_train_drop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing most of the highly correlated features, it appears that past returns, past volatility, SMA (Simple Moving Average), OC (Open-Close), HL (High-Low), and Sign have significant predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_drop = X_test.drop(drop_correlated_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the scale of our data once more before proceeding with feature transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study the distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(X_train_drop))\n",
    "plt.xlabel(' ')\n",
    "plt.title('Boxplot of Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only remaining feature with a high value is `SMA_60`. We will scale this feature using `MinMaxScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = ColumnTransformer([\n",
    "    ('scaled', MinMaxScaler(), ['SMA_60'])\n",
    "],remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "sma_60 = minmax.fit_transform(X_train_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dropped_scaled = pd.DataFrame(\n",
    "    sma_60, columns=minmax.get_feature_names_out(),\n",
    "    index=X_train_drop.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dropped_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our scaled data once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(X_train_dropped_scaled))\n",
    "plt.xlabel('After scaled')\n",
    "plt.title('Boxplot of Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the `OC` and `HL` columns contain a substantial number of outliers. We will employ the `RobustScaler` to transform these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust = ColumnTransformer([\n",
    "        ('cols', RobustScaler(), ['OC','HL'])\n",
    "    ],remainder = 'passthrough')\n",
    "\n",
    "oc_hl = robust.fit_transform(X_train_drop)\n",
    "\n",
    "X_train_dropped_scaled = pd.DataFrame(\n",
    "    oc_hl, columns=robust.get_feature_names_out(),\n",
    "    index=X_train_drop.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(X_train_dropped_scaled.drop(['remainder__SMA_60'],axis=1)))\n",
    "plt.xlabel('After scaled')\n",
    "plt.title('Boxplot of Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct a preprocessing transformer that applies the specified transformations to particular columns. We will fit and transform the training data and subsequently transform the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "preprocessing = ColumnTransformer([\n",
    "        ('MinMax', MinMaxScaler(), ['SMA_60']),\n",
    "        ['Robust', RobustScaler(),['OC','HL'] ]\n",
    "    ],remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform train set\n",
    "train_transformed = preprocessing.fit_transform(X_train_drop)\n",
    "X_train_transformed = pd.DataFrame(\n",
    "    train_transformed, columns=preprocessing.get_feature_names_out(),\n",
    "    index=X_train_drop.index)\n",
    "\n",
    "# Transform test set\n",
    "test_transformed = preprocessing.transform(X_test_drop)\n",
    "X_test_transformed = pd.DataFrame(\n",
    "    test_transformed, columns=preprocessing.get_feature_names_out(),\n",
    "    index=X_test_drop.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the default settings of some classifiers using the cross-validation technique to identify potential candidates for our final model. Additionally, we will use the `class_weight` parameter to address the previously identified class imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify estimators\n",
    "random_state = 42\n",
    "dtc = DecisionTreeClassifier(class_weight=class_weight)\n",
    "rfc = RandomForestClassifier(max_depth = 5 ,class_weight=class_weight, random_state=random_state)\n",
    "knn = KNeighborsClassifier()\n",
    "gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "svc = SVC(class_weight=class_weight, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cv scores\n",
    "clf = [dtc, rfc, knn, gbc, svc]\n",
    "for estimator in clf:\n",
    "    score = cross_val_score(estimator, X_train_transformed, y_train, scoring = 'accuracy', cv=tscv, n_jobs=-1)\n",
    "    print(f\"The accuracy score of {estimator} is: {score.mean():0.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the `RandomForestClassifier()` and `KNeighborsClassifier()` have the highest scores. Given that the `KNeighborsClassifier()` may not perform well with imbalanced classes, we will concentrate on building the model using the `RandomForestClassifier()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default values for the parameters that determine the size of the trees (e.g., `max_depth`, `min_samples_leaf`, etc.) result in fully grown and unpruned trees, which have the potential to overfit our model. To address this, I will set `max_depth` to 5 and then fine-tune this hyperparameter later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(max_depth = 5, class_weight=class_weight, random_state=random_state)\n",
    "base_model.fit(X_train_transformed,y_train)\n",
    "print (classification_report(y_train[-252:], base_model.predict(X_train_transformed[-252:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyper-params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will obtain all the parameters and define our hyperparameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight=class_weight, random_state=random_state, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, we will include `max_depth`, `max_leaf_nodes`, and `n_estimators` in our hyperparameter grid for tuning to prevent overfitting. Additionally, since we are dealing with an imbalanced classification problem, we will experiment with different loss functions to determine their impact on model performance during the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter optimization\n",
    "param_grid = {  'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                'max_depth': [80, 90, 100, 110],\n",
    "                'max_features': [2, 3],\n",
    "                'min_samples_leaf': [3, 4, 5],\n",
    "                'min_samples_split': [8, 10, 12],\n",
    "                'n_estimators': [100, 200, 300, 1000]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform random search\n",
    "gs = GridSearchCV(model, param_grid, scoring='f1', cv=tscv, verbose=0, n_jobs=-1)\n",
    "gs.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fine-tuning our model and conducting a search for the best hyperparameters, we will evaluate our model's performance and compare it to our base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the XGB Classifier with the best params\n",
    "final_model = RandomForestClassifier(class_weight=class_weight, random_state=random_state, n_jobs=-1, **gs.best_params_)\n",
    "final_model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test dataset\n",
    "y_pred = final_model.predict(X_test_transformed)\n",
    "# Measure Accuracy\n",
    "acc_train = accuracy_score(y_train, final_model.predict(X_train_transformed))\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "# Print Accuracy\n",
    "print(f'\\n Training Accuracy \\t: {acc_train :0.4} \\n Test Accuracy \\t\\t: {acc_test :0.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final model outperforms the base model, but it appears to suffer from severe overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "score = cross_val_score(final_model,X_train_transformed,y_train,cv=tscv)\n",
    "print(f'Mean CV Score : {score.mean():0.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "feature_imp = pd.DataFrame({'Importance Score': final_model.feature_importances_,'Features': X_train_transformed.columns}).sort_values(by='Importance Score', ascending=False)\n",
    "sns.barplot(x=feature_imp['Importance Score'], y=feature_imp['Features'])\n",
    "ax.set_title('Features Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the most important features are the asset returns, volatilities, and H-L (High-Low) values. There is some predictive power in the `SMA_60` feature, while the `Sign` feature contributes almost no predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confussion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        final_model,\n",
    "        X_test_transformed,\n",
    "        y_test,\n",
    "        display_labels=final_model.classes_,\n",
    "        cmap=plt.cm.Blues\n",
    "    )   \n",
    "disp.ax_.set_title('Final Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is performing well when predicting the majority class but struggles when predicting the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ROCCurve\n",
    "disp_roc = RocCurveDisplay.from_estimator(\n",
    "        final_model,\n",
    "        X_test_transformed,\n",
    "        y_test,\n",
    "        name='Tuned Random Forest')\n",
    "disp_roc.ax_.set_title('ROC Curve')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the ROC curve, it becomes evident that our model's performance is only marginally better than random chance. This suggests that the model may not effectively discriminate between positive and negative outcomes. To enhance its predictive power and better address the minority class, we may need to further refine our model or consider additional strategies such as resampling techniques or employing different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving final model\n",
    "from joblib import dump, load\n",
    "dump(clf, 'final_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
